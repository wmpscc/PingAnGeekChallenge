{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 64)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homePath = 'game'\n",
    "trainPath = os.path.join(homePath, 'train_ALL.csv')\n",
    "trainData = pd.read_csv(trainPath)\n",
    "testPath = os.path.join(homePath, 'test_ALL.csv')\n",
    "testData = pd.read_csv(testPath)\n",
    "submPath = os.path.join(homePath, 'submission.csv')\n",
    "submData = pd.read_csv(submPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData['emp_length'].fillna(trainData['emp_length'].median(), inplace=True)\n",
    "trainData['annual_inc'].fillna(trainData['annual_inc'].median(), inplace=True)\n",
    "trainData['title'].fillna(trainData['title'].median(), inplace=True)\n",
    "trainData['pub_rec'].fillna(trainData['pub_rec'].median(), inplace=True)\n",
    "trainData['revol_util'].fillna(trainData['revol_util'].median(), inplace=True)\n",
    "trainData['total_acc'].fillna(trainData['total_acc'].median(), inplace=True)\n",
    "trainData['collections_12_mths_ex_med'].fillna(trainData['collections_12_mths_ex_med'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData['emp_length'].fillna(testData['emp_length'].median(), inplace=True)\n",
    "testData['annual_inc'].fillna(testData['annual_inc'].median(), inplace=True)\n",
    "testData['title'].fillna(testData['title'].median(), inplace=True)\n",
    "testData['pub_rec'].fillna(testData['pub_rec'].median(), inplace=True)\n",
    "testData['revol_util'].fillna(testData['revol_util'].median(), inplace=True)\n",
    "testData['total_acc'].fillna(testData['total_acc'].median(), inplace=True)\n",
    "testData['collections_12_mths_ex_med'].fillna(testData['collections_12_mths_ex_med'].median(), inplace=True)\n",
    "del testData['member_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "def calc_f2(label, predict):\n",
    "    p = precision_score(label, predict)\n",
    "    r = recall_score(label, predict)\n",
    "    f2_score = 5*p*r / (4*p + r)\n",
    "    return f2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trueData = trainData.loc[trainData['acc_now_delinq'] == 1]\n",
    "# trainData_copy = trainData.copy()\n",
    "# delLocal = np.array(np.where(np.array(trainData['acc_now_delinq']) == 1))\n",
    "# for i in delLocal.tolist():\n",
    "#     trainData_copy.drop(i, axis=0, inplace=True)\n",
    "# notBlankIndex = np.where(np.array(trainData_copy['member_id']) > 0)\n",
    "# trainData_copy = trainData_copy.loc[notBlankIndex].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainLabel = trainData['acc_now_delinq']\n",
    "del trainData['acc_now_delinq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLabel = list(map(int, trainLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subTrain = pd.concat([trueData, trainData_copy[:3139]], axis=0, ignore_index=True).reset_index()\n",
    "# subLabel = subTrain['acc_now_delinq']\n",
    "subTrain = trainData\n",
    "subLabel = trainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>annual_inc_joint</th>\n",
       "      <th>dti_joint</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_il_6m</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8875.0</td>\n",
       "      <td>8875.0</td>\n",
       "      <td>8875.0</td>\n",
       "      <td>36</td>\n",
       "      <td>18.25</td>\n",
       "      <td>321.97</td>\n",
       "      <td>400</td>\n",
       "      <td>540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>443557</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>291071</td>\n",
       "      <td>201403</td>\n",
       "      <td>45248</td>\n",
       "      <td>0</td>\n",
       "      <td>524215</td>\n",
       "      <td>331275.0</td>\n",
       "      <td>5579</td>\n",
       "      <td>56880</td>\n",
       "      <td>23.65</td>\n",
       "      <td>1985020</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10020.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6078.11000</td>\n",
       "      <td>6078.11</td>\n",
       "      <td>3124.16</td>\n",
       "      <td>1705.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1248.56</td>\n",
       "      <td>224.7408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.652684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886868</td>\n",
       "      <td>167112.315780</td>\n",
       "      <td>-32.431020</td>\n",
       "      <td>742.845442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144784.000000</td>\n",
       "      <td>1.104076</td>\n",
       "      <td>0.390972</td>\n",
       "      <td>1.126292</td>\n",
       "      <td>0.736275</td>\n",
       "      <td>-8.332643</td>\n",
       "      <td>18821.255670</td>\n",
       "      <td>77.465036</td>\n",
       "      <td>2.272958</td>\n",
       "      <td>2.602202</td>\n",
       "      <td>638.616125</td>\n",
       "      <td>60.101450</td>\n",
       "      <td>16700.000000</td>\n",
       "      <td>1.603401</td>\n",
       "      <td>-1.144795</td>\n",
       "      <td>0.872841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>12475.0</td>\n",
       "      <td>36</td>\n",
       "      <td>8.90</td>\n",
       "      <td>396.92</td>\n",
       "      <td>700</td>\n",
       "      <td>930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>443557</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>329558</td>\n",
       "      <td>201205</td>\n",
       "      <td>207723</td>\n",
       "      <td>0</td>\n",
       "      <td>524215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>338</td>\n",
       "      <td>9282</td>\n",
       "      <td>10.58</td>\n",
       "      <td>1992070</td>\n",
       "      <td>91.980157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13202.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14287.61483</td>\n",
       "      <td>14259.05</td>\n",
       "      <td>12500.00</td>\n",
       "      <td>1787.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.821962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886868</td>\n",
       "      <td>274008.533695</td>\n",
       "      <td>-136.302086</td>\n",
       "      <td>1626.923030</td>\n",
       "      <td>-9.647884</td>\n",
       "      <td>122551.893522</td>\n",
       "      <td>-1.922435</td>\n",
       "      <td>-4.268232</td>\n",
       "      <td>-0.548076</td>\n",
       "      <td>-3.280653</td>\n",
       "      <td>-47.701204</td>\n",
       "      <td>-34295.479682</td>\n",
       "      <td>71.375772</td>\n",
       "      <td>0.387501</td>\n",
       "      <td>-3.714946</td>\n",
       "      <td>864.813907</td>\n",
       "      <td>54.964590</td>\n",
       "      <td>12603.076099</td>\n",
       "      <td>0.930222</td>\n",
       "      <td>-3.661237</td>\n",
       "      <td>-7.137984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33600.0</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>60</td>\n",
       "      <td>18.55</td>\n",
       "      <td>863.31</td>\n",
       "      <td>300</td>\n",
       "      <td>420</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>356117</td>\n",
       "      <td>101300.0</td>\n",
       "      <td>329558</td>\n",
       "      <td>201509</td>\n",
       "      <td>601779</td>\n",
       "      <td>0</td>\n",
       "      <td>524215</td>\n",
       "      <td>331275.0</td>\n",
       "      <td>314</td>\n",
       "      <td>59265</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2001050</td>\n",
       "      <td>71.683884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21467.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32552.24</td>\n",
       "      <td>32552.24</td>\n",
       "      <td>2555.30000</td>\n",
       "      <td>2555.30</td>\n",
       "      <td>1047.76</td>\n",
       "      <td>1507.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.917049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886868</td>\n",
       "      <td>148742.329589</td>\n",
       "      <td>18.451757</td>\n",
       "      <td>233.910390</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>106215.000000</td>\n",
       "      <td>1.266193</td>\n",
       "      <td>2.725692</td>\n",
       "      <td>1.069500</td>\n",
       "      <td>2.110409</td>\n",
       "      <td>17.901927</td>\n",
       "      <td>41924.879032</td>\n",
       "      <td>69.954666</td>\n",
       "      <td>1.435041</td>\n",
       "      <td>3.286816</td>\n",
       "      <td>6689.198964</td>\n",
       "      <td>62.386586</td>\n",
       "      <td>41300.000000</td>\n",
       "      <td>1.343599</td>\n",
       "      <td>1.081127</td>\n",
       "      <td>2.358519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>9.71</td>\n",
       "      <td>358.78</td>\n",
       "      <td>600</td>\n",
       "      <td>900</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>443557</td>\n",
       "      <td>47840.0</td>\n",
       "      <td>291071</td>\n",
       "      <td>201308</td>\n",
       "      <td>207723</td>\n",
       "      <td>0</td>\n",
       "      <td>524215</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>3231</td>\n",
       "      <td>56880</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1988090</td>\n",
       "      <td>98.539896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18702.48000</td>\n",
       "      <td>18702.48</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>1702.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.747776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886868</td>\n",
       "      <td>214456.130323</td>\n",
       "      <td>-92.137796</td>\n",
       "      <td>1176.832154</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>129416.000000</td>\n",
       "      <td>-0.978370</td>\n",
       "      <td>-4.449777</td>\n",
       "      <td>-0.325003</td>\n",
       "      <td>-2.045646</td>\n",
       "      <td>-15.277672</td>\n",
       "      <td>-35269.817955</td>\n",
       "      <td>62.797042</td>\n",
       "      <td>0.578704</td>\n",
       "      <td>-1.830720</td>\n",
       "      <td>235.135755</td>\n",
       "      <td>23.704306</td>\n",
       "      <td>22800.000000</td>\n",
       "      <td>0.664909</td>\n",
       "      <td>-2.409980</td>\n",
       "      <td>-4.899681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>16.99</td>\n",
       "      <td>347.87</td>\n",
       "      <td>400</td>\n",
       "      <td>540</td>\n",
       "      <td>266.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>356117</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>329558</td>\n",
       "      <td>201507</td>\n",
       "      <td>6253</td>\n",
       "      <td>0</td>\n",
       "      <td>524215</td>\n",
       "      <td>331275.0</td>\n",
       "      <td>1803</td>\n",
       "      <td>26742</td>\n",
       "      <td>31.85</td>\n",
       "      <td>1999030</td>\n",
       "      <td>84.653259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4167.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13230.24</td>\n",
       "      <td>13230.24</td>\n",
       "      <td>1712.92000</td>\n",
       "      <td>1712.92</td>\n",
       "      <td>769.76</td>\n",
       "      <td>943.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.823131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886868</td>\n",
       "      <td>64931.852199</td>\n",
       "      <td>16.551495</td>\n",
       "      <td>230.159411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15589.000000</td>\n",
       "      <td>1.250887</td>\n",
       "      <td>2.853539</td>\n",
       "      <td>0.993622</td>\n",
       "      <td>1.926283</td>\n",
       "      <td>15.918851</td>\n",
       "      <td>32266.409930</td>\n",
       "      <td>75.753354</td>\n",
       "      <td>1.397840</td>\n",
       "      <td>3.048916</td>\n",
       "      <td>2673.758207</td>\n",
       "      <td>58.816784</td>\n",
       "      <td>10300.000000</td>\n",
       "      <td>1.097526</td>\n",
       "      <td>0.676771</td>\n",
       "      <td>2.127427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  funded_amnt_inv  term  int_rate  installment  \\\n",
       "0     8875.0       8875.0           8875.0    36     18.25       321.97   \n",
       "1    12500.0      12500.0          12475.0    36      8.90       396.92   \n",
       "2    33600.0      33600.0          33600.0    60     18.55       863.31   \n",
       "3    17000.0      17000.0          17000.0    60      9.71       358.78   \n",
       "4    14000.0      14000.0          14000.0    60     16.99       347.87   \n",
       "\n",
       "   grade  sub_grade  emp_title  emp_length  home_ownership  annual_inc  \\\n",
       "0    400        540        1.0        90.0          443557     55000.0   \n",
       "1    700        930        1.0        20.0          443557     43000.0   \n",
       "2    300        420       25.0       100.0          356117    101300.0   \n",
       "3    600        900        3.0       110.0          443557     47840.0   \n",
       "4    400        540      266.0        60.0          356117     30000.0   \n",
       "\n",
       "   verification_status  issue_d  loan_status  pymnt_plan  purpose     title  \\\n",
       "0               291071   201403        45248           0   524215  331275.0   \n",
       "1               329558   201205       207723           0   524215       1.0   \n",
       "2               329558   201509       601779           0   524215  331275.0   \n",
       "3               291071   201308       207723           0   524215    4350.0   \n",
       "4               329558   201507         6253           0   524215  331275.0   \n",
       "\n",
       "   zip_code  addr_state    dti  earliest_cr_line  mths_since_last_record  \\\n",
       "0      5579       56880  23.65           1985020               50.000000   \n",
       "1       338        9282  10.58           1992070               91.980157   \n",
       "2       314       59265  20.00           2001050               71.683884   \n",
       "3      3231       56880   4.01           1988090               98.539896   \n",
       "4      1803       26742  31.85           1999030               84.653259   \n",
       "\n",
       "   pub_rec  revol_bal  revol_util  total_acc  initial_list_status  out_prncp  \\\n",
       "0      1.0    10020.0        60.0       31.0                    1       0.00   \n",
       "1      0.0    13202.0        88.0       18.0                    1       0.00   \n",
       "2      0.0    21467.0        52.0       27.0                    0   32552.24   \n",
       "3      0.0     6585.0        28.9       14.0                    0       0.00   \n",
       "4      0.0     4167.0        40.5       21.0                    0   13230.24   \n",
       "\n",
       "   out_prncp_inv  total_pymnt  total_pymnt_inv  total_rec_prncp  \\\n",
       "0           0.00   6078.11000          6078.11          3124.16   \n",
       "1           0.00  14287.61483         14259.05         12500.00   \n",
       "2       32552.24   2555.30000          2555.30          1047.76   \n",
       "3           0.00  18702.48000         18702.48         17000.00   \n",
       "4       13230.24   1712.92000          1712.92           769.76   \n",
       "\n",
       "   total_rec_int  total_rec_late_fee  recoveries  collection_recovery_fee  \\\n",
       "0        1705.39                 0.0     1248.56                 224.7408   \n",
       "1        1787.61                 0.0        0.00                   0.0000   \n",
       "2        1507.54                 0.0        0.00                   0.0000   \n",
       "3        1702.48                 0.0        0.00                   0.0000   \n",
       "4         943.16                 0.0        0.00                   0.0000   \n",
       "\n",
       "   collections_12_mths_ex_med  mths_since_last_major_derog  policy_code  \\\n",
       "0                         0.0                    45.652684          1.0   \n",
       "1                         0.0                    41.821962          1.0   \n",
       "2                         0.0                    45.917049          1.0   \n",
       "3                         0.0                    43.747776          1.0   \n",
       "4                         0.0                    46.823131          1.0   \n",
       "\n",
       "   application_type  annual_inc_joint   dti_joint  verification_status_joint  \\\n",
       "0            886868     167112.315780  -32.431020                 742.845442   \n",
       "1            886868     274008.533695 -136.302086                1626.923030   \n",
       "2            886868     148742.329589   18.451757                 233.910390   \n",
       "3            886868     214456.130323  -92.137796                1176.832154   \n",
       "4            886868      64931.852199   16.551495                 230.159411   \n",
       "\n",
       "   tot_coll_amt    tot_cur_bal  open_acc_6m  open_il_6m  open_il_12m  \\\n",
       "0      0.000000  144784.000000     1.104076    0.390972     1.126292   \n",
       "1     -9.647884  122551.893522    -1.922435   -4.268232    -0.548076   \n",
       "2    770.000000  106215.000000     1.266193    2.725692     1.069500   \n",
       "3    102.000000  129416.000000    -0.978370   -4.449777    -0.325003   \n",
       "4      0.000000   15589.000000     1.250887    2.853539     0.993622   \n",
       "\n",
       "   open_il_24m  mths_since_rcnt_il  total_bal_il    il_util  open_rv_12m  \\\n",
       "0     0.736275           -8.332643  18821.255670  77.465036     2.272958   \n",
       "1    -3.280653          -47.701204 -34295.479682  71.375772     0.387501   \n",
       "2     2.110409           17.901927  41924.879032  69.954666     1.435041   \n",
       "3    -2.045646          -15.277672 -35269.817955  62.797042     0.578704   \n",
       "4     1.926283           15.918851  32266.409930  75.753354     1.397840   \n",
       "\n",
       "   open_rv_24m   max_bal_bc   all_util  total_rev_hi_lim    inq_fi  \\\n",
       "0     2.602202   638.616125  60.101450      16700.000000  1.603401   \n",
       "1    -3.714946   864.813907  54.964590      12603.076099  0.930222   \n",
       "2     3.286816  6689.198964  62.386586      41300.000000  1.343599   \n",
       "3    -1.830720   235.135755  23.704306      22800.000000  0.664909   \n",
       "4     3.048916  2673.758207  58.816784      10300.000000  1.097526   \n",
       "\n",
       "   total_cu_tl  inq_last_12m  \n",
       "0    -1.144795      0.872841  \n",
       "1    -3.661237     -7.137984  \n",
       "2     1.081127      2.358519  \n",
       "3    -2.409980     -4.899681  \n",
       "4     0.676771      2.127427  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del subTrain['member_id']\n",
    "# del trainData['member_id']\n",
    "# # del subTrain['acc_now_delinq']\n",
    "# trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# # max_depth=13, min_samples_split=50, min_samples_leaf=20, max_features=9,\n",
    "# rnd_clf = RandomForestClassifier(n_estimators=60,  min_samples_split=50, max_depth=13, max_features=9,  oob_score=True)\n",
    "# rnd_clf.fit(subTrain, subLabel)\n",
    "# rnd_pred = rnd_clf.predict(trainData)\n",
    "# rnd_f2 = calc_f2(trainLabel, rnd_pred)\n",
    "# rnd_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rnd_pred_prob = rnd_clf.predict_proba(trainData)[:, 1]\n",
    "# print(metrics.accuracy_score(trainLabel, rnd_pred))\n",
    "# print(metrics.roc_auc_score(trainLabel, rnd_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# bag_rnd = BaggingClassifier(rnd_clf, n_estimators=10, max_samples=1000, bootstrap=True, n_jobs=-1)\n",
    "# bag_rnd.fit(subTrain, subLabel)\n",
    "# rnd_pred = bag_rnd.predict(trainData)\n",
    "# rnd_f2 = calc_f2(trainLabel, rnd_pred)\n",
    "# rnd_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import cross_validation, metrics\n",
    "# gbdt = GradientBoostingClassifier(learning_rate=0.05, min_samples_split=320, min_samples_leaf=7, max_depth=7, \n",
    "#                                  max_features='sqrt', subsample=0.7, random_state=10)\n",
    "# gbdt.fit(subTrain, subLabel)\n",
    "# y_pred = gbdt.predict(trainData)\n",
    "# y_pred_prob = gbdt.predict_proba(trainData)[:, 1]\n",
    "# print(metrics.accuracy_score(trainLabel, y_pred))\n",
    "# print(metrics.roc_auc_score(trainLabel, y_pred_prob))\n",
    "# f2 = calc_f2(trainLabel, y_pred)\n",
    "# f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from xgboost.sklearn import XGBClassifier\n",
    "# xgb1 = XGBClassifier(learning_rate =0.05,\n",
    "#                      n_estimators=1000,\n",
    "#                      max_depth=3,\n",
    "#                      min_child_weight=1,\n",
    "#                      gamma=0.1,\n",
    "#                      subsample=0.8,\n",
    "#                      colsample_bytree=0.8,\n",
    "#                      objective= 'binary:logistic',\n",
    "#                      nthread=4,\n",
    "#                      reg_alpha=0.001,\n",
    "#                      reg_lambda=0.001,\n",
    "#                      scale_pos_weight=1,\n",
    "#                      seed=27)\n",
    "# xgb1.fit(subTrain, subLabel)\n",
    "# xgb1_pred = xgb1.predict(trainData)\n",
    "# xgb1_pred_prob = xgb1.predict_proba(trainData)[:, 1]\n",
    "# print(metrics.accuracy_score(trainLabel, xgb1_pred))\n",
    "# print(metrics.roc_auc_score(trainLabel, xgb1_pred_prob))\n",
    "# xgb1_f2 = calc_f2(trainLabel, xgb1_pred)\n",
    "# print(xgb1_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# lgbTrainData = lgb.Dataset(subTrain, subLabel)\n",
    "# param = {'lambda_l1':[0.5,0.8,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb_clf = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "#                             boosting_type='gbdt',\n",
    "#                             objective='binary',\n",
    "#                             n_estimators=1000,\n",
    "#                             metric='auc',\n",
    "#                             max_depth=3,\n",
    "#                             num_leaves=5,\n",
    "#                             subsample=0.7,\n",
    "#                             colsample_bytree=0.7,\n",
    "#                             min_data_in_leaf=450,\n",
    "#                             feature_fraction=0.7,\n",
    "#                             bagging_fraction=0.7,\n",
    "#                             bagging_freq=6,\n",
    "#                             lambda_l1=1,\n",
    "#                             lambda_l2=0.001,\n",
    "#                             min_gain_to_split=0.265,\n",
    "#                             verbose=5,\n",
    "#                             is_unbalance=True,\n",
    "#                             random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb_clf.fit(subTrain, subLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb_clf_pred = lgb_clf.predict(trainData)\n",
    "# lgb_f2 = calc_f2(trainLabel, lgb_clf_pred)\n",
    "# lgb_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gsearch2 = GridSearchCV(estimator=lgb_clf, param_grid=param, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "# gsearch2.fit(subTrain, subLabel)\n",
    "# print(gsearch2.best_params_)\n",
    "# print(gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate =0.05,\n",
    "                     n_estimators=1000,\n",
    "                     max_depth=3,\n",
    "                     min_child_weight=1,\n",
    "                     gamma=0.1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     objective= 'binary:logistic',\n",
    "                     nthread=4,\n",
    "                     reg_alpha=0.001,\n",
    "                     reg_lambda=0.001,\n",
    "                     scale_pos_weight=1)\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_clf = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                            boosting_type='gbdt',\n",
    "                            objective='binary',\n",
    "                            n_estimators=1000,\n",
    "                            metric='auc',\n",
    "                            max_depth=3,\n",
    "                            num_leaves=5,\n",
    "                            subsample=0.7,\n",
    "                            colsample_bytree=0.7,\n",
    "                            min_data_in_leaf=450,\n",
    "                            feature_fraction=0.7,\n",
    "                            bagging_fraction=0.7,\n",
    "                            bagging_freq=6,\n",
    "                            lambda_l1=1,\n",
    "                            lambda_l2=0.001,\n",
    "                            min_gain_to_split=0.265,\n",
    "                            verbose=5,\n",
    "                            is_unbalance=True)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt = GradientBoostingClassifier(learning_rate=0.05, min_samples_split=320, min_samples_leaf=7, max_depth=7, \n",
    "                                 max_features='sqrt', subsample=0.7, random_state=10)\n",
    "\n",
    "vot = VotingClassifier(estimators=[('xgb', xgb), ('lgb', lgb_clf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "   ...da=0.0, silent=True, subsample=0.7,\n",
       "        subsample_for_bin=200000, subsample_freq=1, verbose=5))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vot.fit(subTrain,subLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "vot_pred = vot.predict(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# bag_rnd = BaggingClassifier(vot, n_estimators=10, max_samples=10000, bootstrap=True, n_jobs=-1)\n",
    "# bag_rnd.fit(subTrain, subLabel)\n",
    "# rnd_pred = bag_rnd.predict(trainData)\n",
    "# rnd_f2 = calc_f2(trainLabel, rnd_pred)\n",
    "# rnd_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submData['acc_now_delinq'] = vot_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submData.to_csv(submPath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
